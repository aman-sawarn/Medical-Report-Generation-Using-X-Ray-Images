{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVxNIH2B4HcN",
    "outputId": "1f3c6400-a778-43eb-82aa-f2b7e6447cba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-uRnXbs4Hca",
    "outputId": "41a59f30-ee69-4cc3-8d85-cdb10cdac2ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uy3lxfz24Hcg"
   },
   "source": [
    "# 1. Writing a custom layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vjEUC_ph4Hch"
   },
   "source": [
    "before we write custom layers in tensorflow lets see the definition of <b>Layers</b> class\n",
    "\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer'> tf.keras.layers.Layers</a>\n",
    "\n",
    "From the tf documentation\n",
    "<pre>\n",
    "This is the class from which all layers inherit.\n",
    "\n",
    "A layer is a class implementing common neural networks operations, such as convolution, batch norm, etc. These operations require managing weights, losses, updates, and inter-layer connectivity.\n",
    "\n",
    "Users will just instantiate a layer and then treat it as a callable.\n",
    "\n",
    "We recommend that descendants of Layer implement the following methods:\n",
    "\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|                                                                                                                   |\n",
    "|<strong> <font color='green'>def __init__(self, trainable=True, name=None, dtype=None, dynamic=False, **kwargs):</font>                               |\n",
    "+</strong>-------------------------------------------------------------------------------------------------------------------+                                                                                                                 \n",
    "|                                                                                                                   |\n",
    "|* the properties should be set by the user via keyword arguments.                                                  |\n",
    "|                                                                                                                   |\n",
    "|* note that 'dtype', 'input_shape' and 'batch_input_shape' are only applicable to input layers, do not pass these  |\n",
    "|  keywords to non-input layers.                                                                                    |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|* allowed_kwargs = {'input_shape', 'batch_input_shape', 'batch_size', 'weights', 'activity_regularizer','autocast'}|\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "\n",
    "\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|<strong> <font color='green'>def build(self, input_shape)</font></strong>:                                                                                     |                                                                                       +-------------------------------------------------------------------------------------------------------------------+\n",
    "|                                                                                                                   |\n",
    "| * Creates the variables of the layer (optional, for subclass implementers). This is a method that implementers of |\n",
    "|   subclasses of `Layer` or `Model`                                                                                |\n",
    "|                                                                                                                   |\n",
    "| * You can override if you need a state-creation step in-between <em><font color='blue'>layer instantiation</font></em> and <em><font color='blue'>layer call</font></em>.               |\n",
    "|                                                                                                                   |\n",
    "| * This is typically used to create the weights of `Layer` subclasses.                                             |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "| Arguments:                                                                                                        |\n",
    "|    input_shape:                                                                                                   |\n",
    "|    Instance of `TensorShape`, or list of instances of `TensorShape` if the layer expects a list of inputs         |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "| <strong> <font color='green'>def call(self, inputs, **kwargs)</font></strong>:                                                                                |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "| * This is where the layer's logic lives.                                                                          |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|* Arguments:                                                                                                       |\n",
    "|        inputs: Input tensor, or list/tuple of input tensors.                                                      |\n",
    "|        **kwargs: Additional keyword arguments.                                                                    |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|* Returns:                                                                                                         |\n",
    "|        A tensor or list/tuple of tensors.                                                                         |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "    \n",
    "<a href='https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/base_layer.py#L310'>check for more arguments</a>                               \n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|<strong> <font color='green'>def add_weight(self,name=None, shape=None, ..., **kwargs)</font></strong>:                                                        |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|* Adds a new variable to the layer.                                                                                |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|* Arguments:                                                                                                       |\n",
    "|        name : Variable name.                                                                                      |\n",
    "|        shape: Variable shape. Defaults to scalar if unspecified.                                                  |\n",
    "|        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.                                    |\n",
    "|        ...                                                                                                        |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "|* Returns:                                                                                                         |\n",
    "|        The created variable. Usually either a `Variable` or `ResourceVariable` instance.                          |\n",
    "+-------------------------------------------------------------------------------------------------------------------+\n",
    "...\n",
    "there are other functions also availabel, please check this link for better understanding of it\n",
    "<a href='https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/base_layer.py'>base_layer.py</a>\n",
    "\n",
    "</pre>\n",
    "\n",
    "## 1.1 Example\n",
    "super(): https://stackoverflow.com/a/27134600/4084039\n",
    "<img src='https://i.imgur.com/1a8N7gH.png' width=600>\n",
    "\n",
    "## 1.2 Resources\n",
    "Do read this blog for more information: https://www.tensorflow.org/guide/keras/custom_layers_and_models\n",
    "few screenshots from the above blog\n",
    "\n",
    "1.\n",
    "<img src='https://i.imgur.com/SDNQgos.png' width=600>\n",
    "2.\n",
    "<img src='https://i.imgur.com/syqjpux.png' width=600>\n",
    "3. \n",
    "<img src='https://i.imgur.com/PfmYWno.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XANoXdba4Hci"
   },
   "source": [
    "# 2. Writing a custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CODchGN44Hcj"
   },
   "source": [
    "There are three ways to implement a model architecture in TF\n",
    "<img src='https://i.imgur.com/n7DBcoo.png' width=400>\n",
    "The third and final method to implement a model architecture using Keras and TensorFlow 2.0 is called model subclassing.\n",
    "\n",
    "Inside of tf.keras the `Model` class is the root class used to define a model architecture. Since tf.keras utilizes object-oriented programming, we can actually `subclass` the Model class and then insert our architecture definition.\n",
    "\n",
    "<pre>\n",
    "    The `Model` class has the same API as `Layer`, with the following differences:\n",
    "        It exposes built-in training, evaluation, and prediction loops (model.fit(), model.evaluate(), model.predict()).\n",
    "        It exposes the list of its inner layers, via the `model.layers` property.\n",
    "        It exposes saving and serialization APIs.\n",
    "    \n",
    "    <font color='blue'>Effectively, the \"Layer\" class corresponds to what we refer to in the literature as a \"layer\" (as in \"convolution layer\" or \"recurrent layer\") or as a \"block\" (as in \"ResNet block\" or \"Inception block\").\n",
    "\n",
    "    Meanwhile, the \"Model\" class corresponds to what is referred to in the literature as a \"model\" (as in \"deep learning model\") or as a \"network\" (as in \"deep neural network\").\n",
    "    </font>\n",
    "</pre>\n",
    "## 2. 1 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyoCS3t14Hck",
    "outputId": "f6776b34-e0c7-40bc-d422-733a1e9c27b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 32) (32, 2)\n",
      "WARNING:tensorflow:From D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6931\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "myDenseLayer (MyDenseLayer)  multiple                  64        \n",
      "_________________________________________________________________\n",
      "lstm_cell (LSTMCell)         multiple                  4864      \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    multiple                  4864      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 4,928\n",
      "Trainable params: 4,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs, **kwargs):\n",
    "        super().__init__(**kwargs) #https://stackoverflow.com/a/27134600/4084039\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "        \n",
    "    def call(self, input):\n",
    "        print(input.shape,self.kernel.shape)\n",
    "        return tf.matmul(input, self.kernel)\n",
    "\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, num_inputs, num_outputs, rnn_units):\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.dense = MyDenseLayer(num_outputs, name='myDenseLayer') \n",
    "        # we can't use the LSTM layer directly when we are building the custom model\n",
    "        # we need to write like to get the functionality of the LSTM layer\n",
    "        self.lstmcell = tf.keras.layers.LSTMCell(rnn_units)\n",
    "        self.rnn = RNN(self.lstmcell)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def call(self, input):\n",
    "        output = self.rnn(input)\n",
    "        output = self.dense(output)\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "import numpy as np\n",
    "data = np.zeros([10,5,5])\n",
    "y = np.zeros([10,2])\n",
    "\n",
    "model  = MyModel(num_inputs=5, num_outputs=2, rnn_units=32)\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer,loss=loss_object)\n",
    "model.fit(data,y, steps_per_epoch=1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWkns-2P4Hco"
   },
   "source": [
    "# 3. Encode decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0heGU724Hcp"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, input_length, enc_units):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.enc_units= enc_units\n",
    "        self.lstm_output = 0\n",
    "        self.state_h=0\n",
    "        self.state_c=0\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=50, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "        \n",
    "    def call(self, input_sentances, training=True):\n",
    "        print(\"ENCODER ==> INPUT SQUENCES SHAPE :\",input_sentances.shape)\n",
    "        input_embedd                           = self.embedding(input_sentances)\n",
    "        print(\"ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE :\",input_embedd.shape)\n",
    "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
    "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "    def get_states(self):\n",
    "        return self.state_h,self.state_c\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, input_length, dec_units):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.input_length = input_length\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=50, input_length=input_shape,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\")\n",
    "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
    "        \n",
    "    def call(self, target_sentances, state_h, state_c):\n",
    "        print(\"DECODER ==> INPUT SQUENCES SHAPE :\",target_sentances.shape)\n",
    "        target_embedd           = self.embedding(target_sentances)\n",
    "        print(\"WE ARE INITIALIZING DECODER WITH ENCODER STATES :\",state_h.shape, state_c.shape)\n",
    "        lstm_output, _,_        = self.lstm(target_embedd, initial_state=[state_h, state_c])\n",
    "        return lstm_output\n",
    "    \n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, encoder_inputs_length,decoder_inputs_length, output_vocab_size):\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.encoder = Encoder(vocab_size=500, embedding_dim=300, input_length=encoder_inputs_length, enc_units=64)\n",
    "        self.decoder = Decoder(vocab_size=500, embedding_dim=300, input_length=decoder_inputs_length, dec_units=64)\n",
    "        self.dense   = Dense(output_vocab_size, activation='softmax')\n",
    "        \n",
    "        \n",
    "    def call(self, data):\n",
    "        input,output = data[0], data[1]\n",
    "        print(\"=\"*20, \"ENCODER\", \"=\"*20)\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
    "        print(\"-\"*27)\n",
    "        print(\"ENCODER ==> OUTPUT SHAPE\",encoder_output.shape)\n",
    "        print(\"ENCODER ==> HIDDEN STATE SHAPE\",encoder_h.shape)\n",
    "        print(\"ENCODER ==> CELL STATE SHAPE\", encoder_c.shape)\n",
    "        print(\"=\"*20, \"DECODER\", \"=\"*20)\n",
    "        decoder_output                       = self.decoder(output, encoder_h, encoder_c)\n",
    "        output                               = self.dense(decoder_output)\n",
    "        print(\"-\"*27)\n",
    "        print(\"FINAL OUTPUT SHAPE\",output.shape)\n",
    "        print(\"=\"*50)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGIK7HK74Hcs",
    "outputId": "769201e1-e27e-4471-9cf0-7d1cd79c129e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== ENCODER ====================\n",
      "ENCODER ==> INPUT SQUENCES SHAPE : (?, 30)\n",
      "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (?, 30, 50)\n",
      "---------------------------\n",
      "ENCODER ==> OUTPUT SHAPE (?, 30, 64)\n",
      "ENCODER ==> HIDDEN STATE SHAPE (?, 64)\n",
      "ENCODER ==> CELL STATE SHAPE (?, 64)\n",
      "==================== DECODER ====================\n",
      "DECODER ==> INPUT SQUENCES SHAPE : (?, 20)\n",
      "WE ARE INITIALIZING DECODER WITH ENCODER STATES : (?, 64) (?, 64)\n",
      "---------------------------\n",
      "FINAL OUTPUT SHAPE (?, 20, 500)\n",
      "==================================================\n",
      "WARNING:tensorflow:From D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 6.2148\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  54440     \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  54440     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  32500     \n",
      "=================================================================\n",
      "Total params: 141,380\n",
      "Trainable params: 141,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = MyModel(encoder_inputs_length=10,decoder_inputs_length=10,output_vocab_size=500)\n",
    "\n",
    "ENCODER_SEQ_LEN = 30\n",
    "DECODER_SEQ_LEN = 20\n",
    "\n",
    "input = np.random.randint(0, 499, size=(2000, ENCODER_SEQ_LEN))\n",
    "output = np.random.randint(0, 499, size=(2000, DECODER_SEQ_LEN))\n",
    "target = tf.keras.utils.to_categorical(output, 500)\n",
    "\n",
    "# loss_object = loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit([input, output], output, steps_per_epoch=1)\n",
    "\n",
    "\"\"\"\n",
    "or you can try this\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy')\n",
    "model.fit([input, output], target, steps_per_epoch=1)\n",
    "\n",
    "\"\"\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Erzgxtp_4Hcv"
   },
   "source": [
    "# 4. Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ams-PwSG4Hcw"
   },
   "source": [
    "## 4.1 Training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVNbOJ2r4Hcx"
   },
   "source": [
    "<h3 id=\"vanilla-seq2seq\">Vanilla Seq2Seq</h3>\n",
    "\n",
    "<p>The Seq2Seq framework relies on the <strong>encoder-decoder</strong> paradigm. The <strong>encoder</strong> <em>encodes</em> the input sequence, while the <strong>decoder</strong> <em>produces</em> the target sequence</p>\n",
    "\n",
    "<p><strong>Encoder</strong></p>\n",
    "\n",
    "<p>Our input sequence is <code class=\"highlighter-rouge\">how are you</code>. Each word from the input sequence is associated to a vector $ w \\in \\mathbb{R}^d $ (via a lookup table). In our case, we have 3 words, thus our input will be transformed into $ [w_0, w_1, w_2] \\in \\mathbb{R}^{d \\times 3} $. Then, we simply run an LSTM over this sequence of vectors and store the last hidden state outputed by the LSTM: this will be our encoder representation $ e $. Let’s write the hidden states $ [e_0, e_1, e_2] $ (and thus $ e = e_2 $)</p>\n",
    "\n",
    "<table class=\"center-image\" style=\"max-width: 60%\">\n",
    "<tr>\n",
    "<td><img src=\"https://i.imgur.com/nToLTs2.png\" alt=\"Vanilla Encoder\" /></td>\n",
    "</tr>\n",
    "<caption align=\"bottom\"><div class=\"text-center\">Vanilla Encoder</div></caption>\n",
    "</table>\n",
    "<p></p>\n",
    "\n",
    "<p><strong>Decoder</strong></p>\n",
    "\n",
    "<p>Now that we have a vector $ e $ that captures the meaning of the input sequence, we’ll use it to generate the target sequence word by word. Feed to another LSTM cell: $ e $ as hidden state and a special <em>start of sentence</em> vector $ w_{sos} $ as input. The LSTM computes the next hidden state $ h_0 \\in \\mathbb{R}^h $. Then, we apply some function $ g : \\mathbb{R}^h \\mapsto \\mathbb{R}^V $ so that $ s_0 := g(h_0) \\in \\mathbb{R}^V $ is a vector of the same size as the vocabulary.</p>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "h_0 &= \\operatorname{LSTM}\\left(e, w_{sos} \\right)\\\\\n",
    "s_0 &= g(h_0)\\\\\n",
    "p_0 &= \\operatorname{softmax}(s_0)\\\\\n",
    "i_0 &= \\operatorname{argmax}(p_0)\\\\\n",
    "\\end{align*} $$\n",
    "\n",
    "<p>Then, apply a softmax to $ s_0 $ to normalize it into a vector of probabilities $ p_0 \\in \\mathbb{R}^V $ . Now, each entry of $ p_0 $ will measure how likely is each word in the vocabulary. Let’s say that the word <em>“comment”</em> has the highest probability (and thus $ i_0 = \\operatorname{argmax}(p_0) $ corresponds to the index of <em>“comment”</em>). Get a corresponding vector $ w_{i_0} = w_{comment} $ and repeat the procedure: the LSTM will take $ h_0 $ as hidden state and $ w_{comment} $ as input and will output a probability vector $ p_1 $ over the second word, etc.</p>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "h_1 &= \\operatorname{LSTM}\\left(h_0, w_{i_0} \\right)\\\\\n",
    "s_1 &= g(h_1)\\\\\n",
    "p_1 &= \\operatorname{softmax}(s_1)\\\\\n",
    "i_1 &= \\operatorname{argmax}(p_1)\n",
    "\\end{align*} $$\n",
    "\n",
    "<p>The decoding stops when the predicted word is a special <em>end of sentence</em> token.</p>\n",
    "\n",
    "<table class=\"center-image\" style=\"max-width: 60%\">\n",
    "<tr>\n",
    "<td><img src=\"https://i.imgur.com/WEPJChD.png\" alt=\"Vanilla Decoder\" /></td>\n",
    "</tr>\n",
    "<caption align=\"bottom\"><div class=\"text-center\">Vanilla Decoder</div></caption>\n",
    "</table>\n",
    "<p></p>\n",
    "\n",
    "<blockquote>\n",
    "  <p>Intuitively, the hidden vector represents the “amount of meaning” that has not been decoded yet.</p>\n",
    "</blockquote>\n",
    "\n",
    "<p>The above method aims at modelling the distribution of the next word conditionned on the beginning of the sentence</p>\n",
    "\n",
    "$$\\mathbb{P}\\left[ y_{t+1} | y_1, \\dots, y_{t}, x_0, \\dots, x_n \\right]$$\n",
    "\n",
    "<p>by writing</p>\n",
    "\n",
    "$$\\mathbb{P}\\left[ y_{t+1} | y_t, h_{t}, e \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jfe9CEDr4Hcy"
   },
   "source": [
    "> in the simple venila seq-seq models, we will pass the last time step hidden and cell states to the decoder, instead of that, we can do avg-pooling or max-pooling of all the hidden states of encoder and then pass the results as the inputs to the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDunaPf74Hcy"
   },
   "source": [
    "## 4.2 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZK2HGq74Hcz",
    "outputId": "21d56ca3-569a-4103-b9d6-95ddbf88b909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Inference ==============================\n",
      "ENCODER ==> INPUT SQUENCES SHAPE : (1, 30)\n",
      "ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE : (1, 30, 50)\n",
      "-------------------- started predition --------------------\n",
      "at time step 0 the word is 0\n",
      "at time step 0 the word is  [[41]]\n",
      "at time step 0 the word is  [[43]]\n",
      "at time step 0 the word is  [[58]]\n",
      "at time step 0 the word is  [[58]]\n",
      "at time step 0 the word is  [[0]]\n",
      "at time step 0 the word is  [[60]]\n",
      "at time step 0 the word is  [[60]]\n",
      "at time step 0 the word is  [[60]]\n",
      "at time step 0 the word is  [[60]]\n",
      "at time step 0 the word is  [[53]]\n",
      "at time step 0 the word is  [[21]]\n",
      "at time step 0 the word is  [[27]]\n",
      "at time step 0 the word is  [[62]]\n",
      "at time step 0 the word is  [[62]]\n",
      "at time step 0 the word is  [[62]]\n",
      "at time step 0 the word is  [[41]]\n",
      "at time step 0 the word is  [[8]]\n",
      "at time step 0 the word is  [[36]]\n",
      "at time step 0 the word is  [[16]]\n",
      "at time step 0 the word is  [[52]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 30, \"Inference\", \"=\" * 30)\n",
    "enc_output, enc_state_h, enc_state_c = model.layers[0](np.expand_dims(input[0], 0))\n",
    "states_values = [enc_state_h, enc_state_c]\n",
    "pred = []\n",
    "cur_vec = np.zeros((1, 1))\n",
    "print('-'*20,\"started predition\",\"-\"*20)\n",
    "print(\"at time step 0 the word is 0\")\n",
    "for i in range(DECODER_SEQ_LEN):\n",
    "    cur_emb = model.layers[1].embedding(cur_vec)\n",
    "    [infe_output, state_h, state_c] = model.layers[1].lstm(cur_emb, initial_state=states_values)\n",
    "    states_values = [state_h, state_c]\n",
    "    # np.argmax(infe_output) will be a single value, which represents the the index of predicted word\n",
    "    # but to pass this data into next time step embedding layer, we are reshaping it into (1,1) shape\n",
    "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
    "    print(\"at time step 0 the word is \", cur_vec)\n",
    "    pred.append(cur_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2v3uS204Hc2"
   },
   "source": [
    "# 5. Attention Mechanisum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FXRS1Ot4Hc3",
    "outputId": "88a74316-2766-4beb-b968-855006934dd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"https://arxiv.org/pdf/1409.0473.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15427492b70>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"https://arxiv.org/pdf/1409.0473.pdf\", width=800, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mEnmB21c4Hc6",
    "outputId": "13ea0612-af09-46f6-932f-e4491f787b0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"https://arxiv.org/pdf/1508.04025.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x154274923c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"https://arxiv.org/pdf/1508.04025.pdf\", width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5bU3eUz4Hc9"
   },
   "source": [
    "## 5.1 Attention mechanism explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etEgct754Hc9"
   },
   "source": [
    "<img src='https://i.imgur.com/OgxuAaM.jpg' width=\"100%\">\n",
    "\n",
    "<img src='https://i.imgur.com/7VhsNER.jpg' width=\"100%\">\n",
    "\n",
    "<img src='https://i.imgur.com/FIUe33r.jpg' width=\"100%\">\n",
    "\n",
    "<img src='https://i.imgur.com/aAGSfN1.jpg' width=\"100%\">\n",
    "\n",
    "<img src='https://i.imgur.com/oEyRXSB.jpg' width=\"100%\">\n",
    "credit: <a href ='https://guillaumegenthial.github.io/assets/img2latex/seq2seq_attention_mechanism_new.svg'>https://guillaumegenthial.github.io</a>\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "<ul>\n",
    "<li><img src='https://i.imgur.com/wX7RtF8.jpg' width=\"100%\"></li>\n",
    "<li><img src='https://i.imgur.com/Vh01Sf3.jpg' width=\"100%\"></li>\n",
    "<li><img src='https://i.imgur.com/Vh01Sf3.jpg' width=\"100%\"></li>\n",
    "<li><img src='https://i.imgur.com/JWOD8JM.jpg' width=\"100%\"></li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<ul>\n",
    "<li><img src='https://i.imgur.com/A17EPNJ.jpg' width=\"100%\"></li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<ul>\n",
    "<li><img src='https://i.imgur.com/S08e16r.jpg' width=\"100%\"></li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<ul>\n",
    "<li><img src='https://i.imgur.com/1eB1Mrl.jpg' width=\"100%\"></li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<ul>\n",
    "<li><img src='https://i.imgur.com/3f7graC.jpg' width=\"100%\"></li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ol>\n",
    "<img src='https://i.imgur.com/WyKmkOF.jpg' width=\"100%\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-KnAHe04Hc-"
   },
   "source": [
    "## 5.2 Inference and Plotting Attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbZCZjhO4Hc_"
   },
   "source": [
    "### 5.2.1 Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RojQzmqu4Hc_"
   },
   "source": [
    "<li>if you observe the above decoder state the att_weights was not there, we modified the onestep_decoder such that it will return att_weights</li>\n",
    "<li>For every time step in the decoder we are getting the attention weights size=(numeber of encoder units)</li>\n",
    "<li>Consider if ith weight is maximum in att_weights then the ith timestep(word) in encoder is helping more for transilating curent decoder word</li>\n",
    "\n",
    "<img src='https://i.imgur.com/9byegcX.png'>\n",
    "\n",
    "<pre>\n",
    "Encoder output shape : (1, 30, 16)\n",
    "Encoder state shape : (1, 16)\n",
    "-------------------- started predition --------------------\n",
    "at time step 0 the word is  [[0.]]\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "at time step 0 the word is  [[60]] (30,)\n",
    "</pre>\n",
    "Note: the data we have created is completly random and these are the results after we have trained model only for on epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OYrnyY34HdA"
   },
   "source": [
    "### 5.2.2 plotting attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UoEeru14HdB"
   },
   "source": [
    "1. if you have observed the above weights, for each time step in decoder you will get a 30 dimension vector.\n",
    "2. So you can create a matrix with with dimension A = (decoder time steps * encoder time steps)\n",
    "3. note that as there will be padding in both encoder and decoder inputs, you might need to remove the rows and columns if they corresponds to padding token. therefore your matrix A should (decoder tokens * encoder tokens) (except padding token)\n",
    "4. you can use seaboarn to plot the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "joKbj4DE4HdC"
   },
   "source": [
    "# 6. Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oW3phL74HdC"
   },
   "source": [
    "The BLEU score is a string-matching algorithm that provides basic quality metrics for MT researchers and developers.\n",
    "\n",
    "To conduct a BLEU measurement the following is necessary:\n",
    "\n",
    "1. One or more human reference translations. This should be data that has not been used in building the system (training data) and ideally should be unknown to the MT system developer.\n",
    "2. It is generally recommended that 1,000 or more sentences be used to get a meaningful measurement. Too small a sample set can sway the score significantly with just a few sentences that match or do not match well.\n",
    "3. Automated translation output of the exact same source data set.\n",
    "4. A measurement utility that performs the comparison and score calculation. ex: import nltk.translate.bleu_score as bleu\n",
    "\n",
    "The BLEU metric scores a translation on a scale of 0 to 1, in an attempt to measure the adequacy and fluency of the MT output. The closer to 1 the test sentences score, the more overlap there is with their human reference translations and thus, the better the system is deemed to be. BLEU scores are often stated on a scale of 1 to 100 to simplify communication, but this should not be confused with the percentage of accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uK5r8L1k4HdD",
    "outputId": "057b4cf9-0caa-4fde-f721-36d3b41fc555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "reference = ['i am groot'.split(),] # the original\n",
    "\n",
    "translation = 'it is ship'.split() # trasilated using model\n",
    "print('BLEU score: {}'.format(bleu.sentence_bleu(reference, translation)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Seq2SeqImplementation_Reference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
